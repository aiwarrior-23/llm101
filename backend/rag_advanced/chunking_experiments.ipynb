{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import open_ai_key\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(api_key=open_ai_key)\n",
    "model_name = \"gpt-4o\"\n",
    "llm = ChatOpenAI(model_name=model_name, openai_api_key=open_ai_key)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = open_ai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load All the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "import os\n",
    "\n",
    "pdf_folder_path = \"./data\"\n",
    "documents = []\n",
    "for file in os.listdir(pdf_folder_path):\n",
    "    if file.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(pdf_folder_path, file)\n",
    "        loader = PyMuPDFLoader(pdf_path)\n",
    "        documents.extend(loader.load())\n",
    "        \n",
    "print(f\"total documents loaded - {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Length Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "separator = \"\\n\\n\",\n",
    "chunk_size = 1000,\n",
    "chunk_overlap  = 128\n",
    ")\n",
    "chunked_documents  = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "chunk_size = 1000,\n",
    "chunk_overlap  = 128\n",
    ")\n",
    "\n",
    "chunked_documents  = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "text_splitter = SemanticChunker(embedding_model)\n",
    "\n",
    "chunked_documents  = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agentic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.chains import create_extraction_chain\n",
    "from typing import Optional, List\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposition_prompt = hub.pull(\"wfh/proposal-indexing\")\n",
    "proposition_prompt.messages[1].prompt.template = proposition_prompt.messages[1].prompt.template + \"\\n\\n\" + \"This data is regarding HR Policies of India. Generate Proposistions and do decompositions accordingly\"\n",
    "runnable = proposition_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing paragraph 3: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-MleP4eNCIIMjcaTNaMI7A9vQ on tokens per min (TPM): Limit 30000, Used 29001, Requested 1513. Please try again in 1.028s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Done with 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 42\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mbreakk\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'breakk' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m propositions\u001b[38;5;241m.\u001b[39msentences\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Using ThreadPoolExecutor with 5 workers\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_paragraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpara\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "class Sentences(BaseModel):\n",
    "    sentences: List[str] = Field(\n",
    "        description=\"These are the paragraphs from an HR policy\"\n",
    "    )\n",
    "\n",
    "\n",
    "extraction_chain = llm.with_structured_output(Sentences)\n",
    "\n",
    "\n",
    "def get_propositions(text):\n",
    "    runnable_output = runnable.invoke({\"input\": text}).content\n",
    "    propositions = extraction_chain.invoke(runnable_output.sentences)\n",
    "    return propositions\n",
    "\n",
    "\n",
    "essay_propositions = []\n",
    "\n",
    "\n",
    "def process_paragraph(para):\n",
    "    \"\"\"Extracts propositions from a paragraph.\"\"\"\n",
    "    propositions = get_propositions(para.page_content)\n",
    "    return propositions.sentences\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = {\n",
    "        executor.submit(process_paragraph, para): i for i, para in enumerate(documents)\n",
    "    }\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        i = futures[future]  # Get the paragraph index\n",
    "        try:\n",
    "            essay_propositions.extend(future.result())\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing paragraph {i}: {e}\")\n",
    "        print(f\"Done with {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23242/3852689682.py:10: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding=OpenAIEmbeddings(api_key=open_ai_key),\n",
      "/tmp/ipykernel_23242/3852689682.py:14: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=\"vector_store_semantic\", embedding_function=OpenAIEmbeddings(api_key=open_ai_key))\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "def create_or_load_vector_db(chunked_documents, persist_directory, load=True):\n",
    "    if load:\n",
    "        vectordb = Chroma(\n",
    "            persist_directory=persist_directory,\n",
    "            embedding_function=OpenAIEmbeddings(api_key=open_ai_key),\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        vectordb = Chroma.from_documents(\n",
    "            documents=chunked_documents,\n",
    "            embedding=embedding_model,\n",
    "            persist_directory=persist_directory,\n",
    "        )\n",
    "    \n",
    "    return vectordb\n",
    "\n",
    "vectordb = create_or_load_vector_db(chunked_documents, \"./vector_store_agentic\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Retrieval & Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "def create_agent_chain():\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    return llm\n",
    "\n",
    "def get_llm_response(query, vectordb):\n",
    "    chain = create_agent_chain()\n",
    "    matching_docs = vectordb.similarity_search(query)\n",
    "    context = [matching_docs[0].page_content, matching_docs[1].page_content, matching_docs[2].page_content]\n",
    "    prompt = f\"You are a HR policies Expert. Based on the provided context from policies, answer the user question.\\Context: {[' '.join(c) for c in context]}\\nQuestion: {query}\\nAnswer as if you are helpful person answering the user.  Give a concise answer only\"\n",
    "    answer = chain.invoke(prompt)\n",
    "    return answer.content, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu-singh/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.chains import create_extraction_chain\n",
    "from typing import Optional, List\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu-singh/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "obj = hub.pull(\"wfh/proposal-indexing\")\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', openai_api_key = os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decompose the following:\n",
      "{input}\n",
      "\n",
      "This data is regarding HR Policies of India. Generate Proposistions and do decompositions accordingly\n"
     ]
    }
   ],
   "source": [
    "obj.messages[1].prompt.template = obj.messages[1].prompt.template + \"\\n\\n\" + \"This data is regarding HR Policies of India. Generate Proposistions and do decompositions accordingly\"\n",
    "\n",
    "print(obj.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = obj | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu-singh/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1369: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Sentences(BaseModel):\n",
    "    sentences: List[str] = Field(description=\"These are the paragraphs from an HR policy\")\n",
    "    \n",
    "# Extraction\n",
    "extraction_chain = llm.with_structured_output(Sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_propositions(text):\n",
    "    runnable_output = extraction_chain.invoke(text)\n",
    "    propositions = extraction_chain.invoke(runnable_output.sentences)\n",
    "    return propositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 3\n",
      "Done with 1\n",
      "Done with 2\n",
      "Done with 4\n",
      "Done with 5\n",
      "Done with 0\n",
      "Done with 6\n",
      "Done with 7\n",
      "Done with 8\n",
      "Done with 9\n",
      "Done with 10\n",
      "Done with 12\n",
      "Done with 11\n",
      "Done with 13\n",
      "Done with 17\n",
      "Done with 16\n",
      "Done with 15\n",
      "Done with 14\n",
      "Done with 18\n",
      "Done with 19\n",
      "Done with 21\n",
      "Done with 22\n",
      "Done with 20\n",
      "Done with 23\n",
      "Done with 24\n",
      "Done with 27\n",
      "Done with 25\n",
      "Done with 29\n",
      "Done with 26\n",
      "Done with 28\n",
      "Done with 31\n",
      "Done with 32\n",
      "Done with 30\n",
      "Done with 33\n",
      "Done with 37\n",
      "Done with 34\n",
      "Done with 36\n",
      "Done with 38\n",
      "Done with 35\n",
      "Done with 39\n",
      "Done with 40\n",
      "Done with 41\n",
      "Done with 42\n",
      "Done with 43\n",
      "Done with 44\n",
      "Done with 45\n",
      "Done with 50\n",
      "Done with 46\n",
      "Done with 48\n",
      "Done with 49\n",
      "Done with 47\n",
      "Done with 51\n",
      "Done with 53\n",
      "Done with 52\n",
      "Done with 56\n",
      "Done with 57\n",
      "Done with 59\n",
      "Done with 58\n",
      "Done with 60\n",
      "Done with 61\n",
      "Done with 62\n",
      "Done with 55\n",
      "Done with 63\n",
      "Done with 66\n",
      "Done with 67\n",
      "Done with 64\n",
      "Done with 54\n",
      "Done with 65\n",
      "Done with 68\n",
      "Done with 69\n",
      "Done with 70\n",
      "Done with 72\n",
      "Done with 75\n",
      "Done with 71\n",
      "Done with 74\n",
      "Done with 73\n",
      "Done with 77\n",
      "Done with 78\n",
      "Done with 80\n",
      "Done with 81\n",
      "Done with 79\n",
      "Done with 76\n",
      "Done with 83\n",
      "Done with 82\n",
      "Done with 85\n",
      "Done with 84\n",
      "Done with 86\n",
      "Done with 88\n",
      "Done with 89\n",
      "Done with 87\n",
      "Done with 90\n",
      "Done with 92\n",
      "Done with 91\n",
      "Done with 96\n",
      "Done with 93\n",
      "Done with 94\n",
      "Done with 95\n",
      "Done with 97\n",
      "Done with 100\n",
      "Done with 98\n",
      "Done with 99\n",
      "Done with 101\n",
      "Done with 102\n",
      "Done with 107\n",
      "Done with 104\n",
      "Done with 106\n",
      "Done with 103\n",
      "Done with 108\n",
      "Done with 105\n",
      "Done with 110\n",
      "Done with 111\n",
      "Done with 112\n",
      "Done with 113\n",
      "Done with 109\n",
      "Done with 114\n",
      "Done with 115\n",
      "Done with 117\n",
      "Done with 116\n",
      "Done with 118\n",
      "Done with 122\n",
      "Done with 121\n",
      "Done with 119\n",
      "Done with 123\n",
      "Done with 124\n",
      "Done with 125\n",
      "Done with 127\n",
      "Done with 126\n",
      "Done with 130\n",
      "Done with 120\n",
      "Done with 128\n",
      "Done with 129\n",
      "Done with 131\n",
      "Done with 132\n",
      "Done with 134\n",
      "Done with 133\n",
      "Done with 135\n",
      "Done with 138\n",
      "Done with 136\n",
      "Done with 137\n",
      "Done with 142\n",
      "Done with 139\n",
      "Done with 143\n",
      "Done with 140\n",
      "Done with 144\n",
      "Done with 141\n",
      "Done with 146\n",
      "Done with 145\n",
      "Done with 148\n",
      "Done with 149\n",
      "Done with 147\n",
      "Done with 151\n",
      "Done with 152\n",
      "Done with 150\n",
      "Done with 154\n",
      "Done with 157\n",
      "Done with 153\n",
      "Done with 158\n",
      "Done with 155\n",
      "Done with 156\n",
      "Done with 160\n",
      "Done with 159\n",
      "Done with 163\n",
      "Done with 162\n",
      "Done with 161\n",
      "Done with 166\n",
      "Done with 165\n",
      "Done with 164\n",
      "Done with 167\n",
      "Done with 168\n",
      "Done with 170\n",
      "Done with 173\n",
      "Done with 169\n",
      "Done with 171\n",
      "Done with 172\n",
      "Done with 174\n",
      "Done with 176\n",
      "Done with 177\n",
      "Done with 175\n",
      "Done with 178\n",
      "Done with 181\n",
      "Done with 180\n",
      "Done with 183\n",
      "Done with 179\n",
      "Done with 182\n",
      "Done with 184\n",
      "Done with 186\n",
      "Done with 185\n",
      "Done with 187\n",
      "Done with 188\n",
      "Done with 191\n",
      "Done with 190\n",
      "Done with 189\n",
      "Done with 192\n",
      "Done with 194\n",
      "Done with 195\n",
      "Done with 193\n",
      "Done with 197\n",
      "Done with 196\n",
      "Done with 202\n",
      "Done with 198\n",
      "Done with 201\n",
      "Done with 200\n",
      "Done with 203\n",
      "Done with 199\n",
      "Done with 208\n",
      "Done with 206\n",
      "Done with 204\n",
      "Done with 207\n",
      "Done with 209\n",
      "Done with 210\n",
      "Done with 205\n",
      "Done with 211\n",
      "Done with 214\n",
      "Done with 212\n",
      "Done with 218\n",
      "Done with 213\n",
      "Done with 216\n",
      "Done with 217\n",
      "Done with 215\n",
      "Done with 219\n",
      "Done with 221\n",
      "Done with 222\n",
      "Done with 223\n",
      "Done with 224\n",
      "Done with 225\n",
      "Done with 220\n",
      "Done with 226\n",
      "Done with 227\n",
      "Done with 231\n",
      "Done with 228\n",
      "Done with 230\n",
      "Done with 234\n",
      "Done with 229\n",
      "Done with 233\n",
      "Done with 232\n",
      "Done with 235\n",
      "Done with 236\n",
      "Done with 237\n",
      "Done with 238\n",
      "Done with 239\n",
      "Done with 240\n",
      "Done with 241\n",
      "Done with 246\n",
      "Done with 243\n",
      "Done with 244\n",
      "Done with 242\n",
      "Done with 249\n",
      "Done with 245\n",
      "Done with 247\n",
      "Done with 250\n",
      "Done with 252\n",
      "Done with 251\n",
      "Done with 248\n",
      "Done with 253\n",
      "Done with 255\n",
      "Done with 257\n",
      "Done with 254\n",
      "Done with 256\n",
      "Done with 258\n",
      "Done with 259\n",
      "Done with 261\n",
      "Done with 260\n",
      "Done with 262\n",
      "Done with 267\n",
      "Done with 263\n",
      "Done with 264\n",
      "Done with 268\n",
      "Done with 265\n",
      "Done with 269\n",
      "Done with 272\n",
      "Done with 266\n",
      "Done with 273\n",
      "Done with 271\n",
      "Done with 274\n",
      "Done with 275\n",
      "Done with 276\n",
      "Done with 270\n",
      "Done with 277\n",
      "Done with 278\n",
      "Done with 280\n",
      "Done with 279\n",
      "Done with 282\n",
      "Done with 284\n",
      "Done with 287\n",
      "Done with 281\n",
      "Done with 286\n",
      "Done with 285\n",
      "Done with 283\n",
      "Done with 289\n",
      "Done with 292\n",
      "Done with 290\n",
      "Done with 291\n",
      "Done with 293\n",
      "Done with 294\n",
      "Done with 288\n",
      "Done with 295\n",
      "Done with 297\n",
      "Done with 298\n",
      "Done with 296\n",
      "Done with 300\n",
      "Done with 299\n",
      "Done with 301\n",
      "Done with 304\n",
      "Done with 302\n",
      "Done with 303\n",
      "Done with 305\n",
      "Done with 308\n",
      "Done with 306\n",
      "Done with 310\n",
      "Done with 307\n",
      "Done with 309\n",
      "Done with 311\n",
      "Done with 316\n",
      "Done with 312\n",
      "Done with 313\n",
      "Done with 315\n",
      "Done with 314\n",
      "Done with 318\n",
      "Done with 317\n",
      "Done with 319\n",
      "Done with 321\n",
      "Done with 322\n",
      "Done with 323\n",
      "Done with 320\n",
      "Done with 324\n",
      "Done with 325\n",
      "Done with 326\n",
      "Done with 327\n",
      "Done with 328\n",
      "Done with 329\n",
      "Done with 332\n",
      "Done with 331\n",
      "Done with 333\n",
      "Done with 330\n",
      "Done with 336\n",
      "Done with 337\n",
      "Done with 335\n",
      "Done with 334\n",
      "Done with 339\n",
      "Done with 340\n",
      "Done with 338\n",
      "Done with 341\n",
      "Done with 343\n",
      "Done with 345\n",
      "Done with 342\n",
      "Done with 344\n",
      "Done with 346\n",
      "Done with 348\n",
      "Done with 349\n",
      "Done with 347\n",
      "Done with 350\n",
      "Done with 352\n",
      "Done with 351\n",
      "Done with 354\n",
      "Done with 355\n",
      "Done with 353\n",
      "Done with 356\n",
      "Done with 358\n",
      "Done with 357\n",
      "Done with 359\n",
      "Done with 361\n",
      "Done with 360\n",
      "Done with 363\n",
      "Done with 362\n",
      "Done with 367\n",
      "Done with 364\n",
      "Done with 368\n",
      "Done with 365\n",
      "Done with 366\n",
      "Done with 370\n",
      "Done with 371\n",
      "Done with 369\n",
      "Done with 372\n",
      "Done with 373\n",
      "Done with 375\n",
      "Done with 376\n",
      "Done with 377\n",
      "Done with 374\n",
      "Done with 378\n",
      "Done with 380\n",
      "Done with 382\n",
      "Done with 383\n",
      "Done with 379\n",
      "Done with 381\n",
      "Done with 384\n",
      "Done with 385\n",
      "Done with 386\n",
      "Done with 387\n",
      "Done with 390\n",
      "Done with 388\n",
      "Done with 391\n",
      "Done with 393\n",
      "Done with 394\n",
      "Done with 395\n",
      "Done with 398\n",
      "Done with 392\n",
      "Done with 397\n",
      "Done with 396\n",
      "Done with 399\n",
      "Done with 401\n",
      "Done with 400\n",
      "Done with 402\n",
      "Done with 403\n",
      "Done with 405\n",
      "Done with 408\n",
      "Done with 406\n",
      "Done with 404\n",
      "Done with 409\n",
      "Done with 410\n",
      "Done with 411\n",
      "Done with 412\n",
      "Done with 413\n",
      "Done with 414\n",
      "Done with 416\n",
      "Done with 415\n",
      "Done with 417\n",
      "Done with 418\n",
      "Done with 419\n",
      "Done with 420\n",
      "Done with 421\n",
      "Done with 422\n",
      "Done with 423\n",
      "Done with 424\n",
      "Done with 425\n",
      "Done with 426\n",
      "Done with 427\n",
      "Done with 429\n",
      "Done with 428\n",
      "Done with 430\n",
      "Done with 432\n",
      "Done with 434\n",
      "Done with 431\n",
      "Done with 435\n",
      "Done with 433\n",
      "Done with 437\n",
      "Done with 436\n",
      "Done with 438\n",
      "Done with 439\n",
      "Done with 440\n",
      "Done with 441\n",
      "Done with 442\n",
      "Done with 445\n",
      "Done with 443\n",
      "Done with 446\n",
      "Done with 389\n",
      "Done with 444\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(process_paragraph, para): i \u001b[38;5;28;01mfor\u001b[39;00m i, para \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(documents)}\n\u001b[0;32m---> 14\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Get the paragraph index\u001b[39;49;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/concurrent/futures/_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    241\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 243\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m propositions\u001b[38;5;241m.\u001b[39msentences\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Using ThreadPoolExecutor with 5 workers\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_paragraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpara\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "essay_propositions = []\n",
    "\n",
    "def process_paragraph(para):\n",
    "    \"\"\"Extracts propositions from a paragraph.\"\"\"\n",
    "    propositions = get_propositions(para.page_content)\n",
    "    return propositions.sentences\n",
    "\n",
    "# Using ThreadPoolExecutor with 5 workers\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = {executor.submit(process_paragraph, para): i for i, para in enumerate(documents)}\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        i = futures[future]  # Get the paragraph index\n",
    "        try:\n",
    "            essay_propositions.extend(future.result())\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing paragraph {i}: {e}\")\n",
    "        print(f\"Done with {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 5712 propositions\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(essay_propositions)} propositions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "temp_dict = {}\n",
    "\n",
    "temp_dict[\"essay_propositions\"] = essay_propositions\n",
    "\n",
    "with open(\"essay_propositions.json\", 'w') as file:\n",
    "    json.dump(temp_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0 chunks\n",
      "Finished 50 chunks\n",
      "Finished 100 chunks\n",
      "Finished 150 chunks\n",
      "Finished 200 chunks\n",
      "Finished 250 chunks\n",
      "Finished 300 chunks\n",
      "Finished 350 chunks\n",
      "Finished 400 chunks\n",
      "Finished 450 chunks\n",
      "Finished 500 chunks\n",
      "Finished 550 chunks\n",
      "Finished 600 chunks\n",
      "Finished 650 chunks\n",
      "Finished 700 chunks\n",
      "Finished 750 chunks\n",
      "Finished 800 chunks\n",
      "Finished 850 chunks\n",
      "Finished 900 chunks\n",
      "Finished 950 chunks\n",
      "Finished 1000 chunks\n",
      "Finished 1050 chunks\n",
      "Finished 1100 chunks\n",
      "Finished 1150 chunks\n",
      "Finished 1200 chunks\n",
      "Finished 1250 chunks\n",
      "Finished 1300 chunks\n",
      "Finished 1350 chunks\n",
      "Finished 1400 chunks\n",
      "Finished 1450 chunks\n",
      "Finished 1500 chunks\n",
      "Finished 1550 chunks\n",
      "Finished 1600 chunks\n",
      "Finished 1650 chunks\n",
      "Finished 1700 chunks\n",
      "Finished 1750 chunks\n",
      "Finished 1800 chunks\n",
      "Finished 1850 chunks\n",
      "Finished 1900 chunks\n",
      "Finished 1950 chunks\n",
      "Finished 2000 chunks\n",
      "Finished 2050 chunks\n",
      "Finished 2100 chunks\n",
      "Finished 2150 chunks\n",
      "Finished 2200 chunks\n",
      "Finished 2250 chunks\n",
      "Finished 2300 chunks\n",
      "Finished 2350 chunks\n",
      "Finished 2400 chunks\n",
      "Finished 2450 chunks\n",
      "Finished 2500 chunks\n",
      "Finished 2550 chunks\n",
      "Finished 2600 chunks\n",
      "Finished 2650 chunks\n",
      "Finished 2700 chunks\n",
      "Finished 2750 chunks\n",
      "Finished 2800 chunks\n",
      "Finished 2850 chunks\n",
      "Finished 2900 chunks\n",
      "Finished 2950 chunks\n",
      "Finished 3000 chunks\n",
      "Finished 3050 chunks\n",
      "Finished 3100 chunks\n",
      "Finished 3150 chunks\n",
      "Finished 3200 chunks\n",
      "Finished 3250 chunks\n",
      "Finished 3300 chunks\n",
      "Finished 3350 chunks\n",
      "Finished 3400 chunks\n",
      "Finished 3450 chunks\n",
      "Finished 3500 chunks\n",
      "Finished 3550 chunks\n",
      "Finished 3600 chunks\n",
      "Finished 3650 chunks\n",
      "Finished 3700 chunks\n",
      "Finished 3750 chunks\n",
      "Finished 3800 chunks\n",
      "Finished 3850 chunks\n",
      "Finished 3900 chunks\n",
      "Finished 3950 chunks\n",
      "Finished 4000 chunks\n",
      "Finished 4050 chunks\n",
      "Finished 4100 chunks\n",
      "Finished 4150 chunks\n",
      "Finished 4200 chunks\n",
      "Finished 4250 chunks\n",
      "Finished 4300 chunks\n",
      "Finished 4350 chunks\n",
      "Finished 4400 chunks\n",
      "Finished 4450 chunks\n",
      "Finished 4500 chunks\n",
      "Finished 4550 chunks\n",
      "Finished 4600 chunks\n",
      "Finished 4650 chunks\n",
      "Finished 4700 chunks\n",
      "Finished 4750 chunks\n",
      "Finished 4800 chunks\n",
      "Finished 4850 chunks\n",
      "Finished 4900 chunks\n",
      "Finished 4950 chunks\n",
      "Finished 5000 chunks\n",
      "Finished 5050 chunks\n",
      "Finished 5100 chunks\n",
      "Finished 5150 chunks\n",
      "Finished 5200 chunks\n",
      "Finished 5250 chunks\n",
      "Finished 5300 chunks\n",
      "Finished 5350 chunks\n",
      "Finished 5400 chunks\n",
      "Finished 5450 chunks\n",
      "Finished 5500 chunks\n",
      "Finished 5550 chunks\n",
      "Finished 5600 chunks\n",
      "Finished 5650 chunks\n",
      "Finished 5700 chunks\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "import json\n",
    "from AgenticChunker import AgenticChunker\n",
    "\n",
    "with open(\"essay_propositions.json\", 'r') as file:\n",
    "    essay_propositions = json.load(file)\n",
    "    \n",
    "essay_propositions = essay_propositions[\"essay_propositions\"]\n",
    "    \n",
    "# Initialize the shared AgenticChunker instance\n",
    "ac = AgenticChunker()\n",
    "\n",
    "def process_single_proposition(proposition):\n",
    "    \"\"\"Worker function to process a single proposition in the shared AgenticChunker instance.\"\"\"\n",
    "    ac.add_proposition(proposition)\n",
    "\n",
    "def process_propositions_parallel(essay_propositions, max_workers=50):\n",
    "    \"\"\"\n",
    "    Processes propositions in parallel using a shared AgenticChunker instance.\n",
    "    Each batch contains at most `max_workers` propositions.\n",
    "    \"\"\"\n",
    "    # Using ThreadPoolExecutor with 10 workers\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submitting the propositions in batches of `max_workers`\n",
    "        for i in range(0, len(essay_propositions), max_workers):\n",
    "            batch = essay_propositions[i:i + max_workers]\n",
    "            futures = [executor.submit(process_single_proposition, prop) for prop in batch]\n",
    "\n",
    "            # Wait for batch completion before submitting the next batch\n",
    "            concurrent.futures.wait(futures)\n",
    "            print(f\"Finished {i} chunks\")\n",
    "    \n",
    "    # Return the final chunks after all propositions are processed\n",
    "    return ac.get_chunks(get_type='dict')\n",
    "\n",
    "# Run parallel processing\n",
    "final_chunks = process_propositions_parallel(essay_propositions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_documents = {}\n",
    "for i, (id, chunk) in enumerate(final_chunks.items()):\n",
    "    final_string = \"\"\n",
    "    final_string += f\"Title: {chunk['title']}\\n\\n\"\n",
    "    final_string += f\"Summary: {chunk['summary']}\\n\\n\"\n",
    "    propositions = [(\"\").join(p) for p in chunk[\"propositions\"]]\n",
    "    final_string += f\"Propositions:\\n {propositions[0]}\"\n",
    "    chunked_documents[f\"chunk_{i}\"] = final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"agentic_chunks.json\", 'w') as file:\n",
    "    json.dump(chunked_documents, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "from config import open_ai_key\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "chunked_documents = [Document(page_content=s) for i, s in enumerate(chunked_documents.values())]\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "documents=chunked_documents,\n",
    "embedding=OpenAIEmbeddings(api_key=open_ai_key),\n",
    "persist_directory=\"./vectofrom langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from config import open_ai_key\n",
    "import json\n",
    "import random\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", api_key=open_ai_key)\n",
    "\n",
    "QUESTIONS_GENERATOR = \"\"\"\n",
    "Given below is a context from one of the HR Policies of India.\n",
    "\n",
    "context: {context}\n",
    "\n",
    "Think about 5 questions that a person may ask whose answer can be given from the context\n",
    "\n",
    "List down 5 questions in json format and json format only. Given below is reference json structure.\n",
    "\n",
    "{{\n",
    "    \"question_1\": {{\"question\": str, \"answer\": str}},\n",
    "    \"question_2\": {{\"question\": str, \"answer\": str}},\n",
    "    \"question_3\": {{\"question\": str, \"answer\": str}},\n",
    "    \"question_4\": {{\"question\": str, \"answer\": str}},\n",
    "    \"question_5\": {{\"question\": str, \"answer\": str}},\n",
    "}}\n",
    "\n",
    "The questions you ask, make sure that the answer can be found in the context. Make sure that tha question and answer is relevant. Dont give vague question or answer. Dont give too general questions or answers.\n",
    "WHile answering the question, name the policy in detail which you are referring to\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Questions(BaseModel):\n",
    "question_1: dict = Field(description=\"First Question\")\n",
    "question_2: dict = Field(description=\"Second Question\")\n",
    "question_3: dict = Field(description=\"Third Question\")\n",
    "question_4: dict = Field(description=\"Fourth Question\")\n",
    "question_5: dict = Field(description=\"Fifth Question\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Questions)\n",
    "\n",
    "question_prompt = PromptTemplate(\n",
    "template=QUESTIONS_GENERATOR,\n",
    "input_variables=[\"context\"],\n",
    "partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = question_prompt | llm | parser\n",
    "\n",
    "final_dict = {}\n",
    "i = 0\n",
    "while True:\n",
    "if i == 20:\n",
    "break\n",
    "document = random.choice(documents)\n",
    "context = document.page_content\n",
    "if len(context) < 30:\n",
    "continue\n",
    "questions = chain.invoke({\"context\" : context})\n",
    "final_dict[f\"batch_{i}\"] = questions\n",
    "i += 1\n",
    "\n",
    "cleaned_data = {}\n",
    "i = 1\n",
    "\n",
    "for batch_key, batch_value in final_dict.items():\n",
    "\n",
    "for question_key, question_value in batch_value.items():\n",
    "\n",
    "    cleaned_data[f\"question_{i}\"] = {\n",
    "        'question': question_value['question'],\n",
    "        'answer': question_value['answer']\n",
    "    }\n",
    "    i+=1\n",
    "\n",
    "with open(\"test_data.json\", \"w\") as file:\n",
    "json.dump(cleaned_data, file, indent=4)r_store_agentic\"\n",
    ")\n",
    "\n",
    "vectordb = Chroma(persist_directory=\"vector_store_agentic\", embedding_function=OpenAIEmbeddings(api_key=open_ai_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In India, the Payment of Wages Act, 1936, applies to employees whose wages do not exceed a certain amount (as notified by the government) and ensures timely payment of wages. According to the Act, wages must be paid by the 7th of the following month if the establishment employs less than 1,000 workers. Therefore, it is generally required for companies in India to pay salaries by the 7th of each month for establishments with fewer than 1,000 employees. Not paying salaries by this date would be considered a violation of the Act. It is advisable to check the specific terms of your employment contract and consult with a legal expert for detailed advice.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llm_response(\"Is it illegal for a company in India (across india) having less than 1000 employees to not pay my salary after 10th? Also tell me the time limit.\", vectordb)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete batch batch_7\n",
      "complete batch batch_0\n",
      "complete batch batch_1\n",
      "complete batch batch_2\n",
      "complete batch batch_5\n",
      "complete batch batch_4\n",
      "complete batch batch_8\n",
      "complete batch batch_3\n",
      "complete batch batch_9\n",
      "complete batch batch_11\n",
      "complete batch batch_6\n",
      "complete batch batch_10\n",
      "complete batch batch_13\n",
      "complete batch batch_16\n",
      "complete batch batch_14\n",
      "complete batch batch_12\n",
      "complete batch batch_17\n",
      "complete batch batch_18\n",
      "complete batch batch_20\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-MleP4eNCIIMjcaTNaMI7A9vQ on tokens per min (TPM): Limit 30000, Used 29559, Requested 785. Please try again in 688ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(process_batch, i): i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m)}\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures):\n\u001b[0;32m---> 68\u001b[0m     batch_key, questions \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     final_dict[batch_key] \u001b[38;5;241m=\u001b[39m questions\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplete batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[37], line 61\u001b[0m, in \u001b[0;36mprocess_batch\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(context) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m30\u001b[39m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m questions \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, questions\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_core/runnables/base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 690\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:792\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 792\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/resources/chat/completions.py:863\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    860\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    861\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1278\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1287\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1288\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1055\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1055\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1071\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1070\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1074\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1075\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1080\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-MleP4eNCIIMjcaTNaMI7A9vQ on tokens per min (TPM): Limit 30000, Used 29559, Requested 785. Please try again in 688ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from config import open_ai_key\n",
    "import json\n",
    "import random\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", api_key=open_ai_key)\n",
    "\n",
    "QUESTIONS_GENERATOR = \"\"\"\n",
    "Given below is a context from one of the HR Policies of India.\n",
    "\n",
    "context: {context}\n",
    "\n",
    "Think about 5 questions that a person may ask whose answer can be given from the context\n",
    "\n",
    "List down 5 questions in json format and json format only. Given below is reference json structure.\n",
    "\n",
    "{{\n",
    "    \"question_1\": {{\"question\": str, \"answer\": str}},\n",
    "    \"question_2\": {{\"question\": str, \"answer\": str}},\n",
    "    \"question_3\": {{\"question\": str, \"answer\": str}},\n",
    "    \"question_4\": {{\"question\": str, \"answer\": str}},\n",
    "    \"question_5\": {{\"question\": str, \"answer\": str}},\n",
    "}}\n",
    "\n",
    "The questions you ask, make sure that the answer can be found in the context. Make sure that tha question and answer is relevant. Dont give vague question or answer. Dont give too general questions or answers.\n",
    "WHile answering the question, name the policy in detail which you are referring to\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Questions(BaseModel):\n",
    "    question_1: dict = Field(description=\"First Question\")\n",
    "    question_2: dict = Field(description=\"Second Question\")\n",
    "    question_3: dict = Field(description=\"Third Question\")\n",
    "    question_4: dict = Field(description=\"Fourth Question\")\n",
    "    question_5: dict = Field(description=\"Fifth Question\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Questions)\n",
    "\n",
    "question_prompt = PromptTemplate(\n",
    "    template=QUESTIONS_GENERATOR,\n",
    "    input_variables=[\"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "chain = question_prompt | llm | parser\n",
    "\n",
    "import concurrent.futures\n",
    "import random\n",
    "\n",
    "final_dict = {}\n",
    "\n",
    "def process_batch(i):\n",
    "    while True:\n",
    "        document = random.choice(documents)\n",
    "        context = document.page_content\n",
    "        if len(context) < 30:\n",
    "            continue\n",
    "        questions = chain.invoke({\"context\": context})\n",
    "        return f\"batch_{i}\", questions\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = {executor.submit(process_batch, i): i for i in range(50)}\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        batch_key, questions = future.result()\n",
    "        final_dict[batch_key] = questions\n",
    "        print(f\"complete batch {batch_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_data = {}\n",
    "i = 1\n",
    "\n",
    "for batch_key, batch_value in final_dict.items():\n",
    "    for question_key, question_value in batch_value.items():\n",
    "        cleaned_data[f\"question_{i}\"] = {\n",
    "            'question': question_value['question'],\n",
    "            'answer': question_value['answer']\n",
    "        }\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_data.json\", \"w\") as file:\n",
    "    json.dump(cleaned_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-MleP4eNCIIMjcaTNaMI7A9vQ on tokens per min (TPM): Limit 30000, Used 28497, Requested 2458. Please try again in 1.91s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(process_llm_response, k, v): k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m cleaned_data\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures):\n\u001b[0;32m---> 14\u001b[0m     k, result \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     llm_response_data[k] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[42], line 7\u001b[0m, in \u001b[0;36mprocess_llm_response\u001b[0;34m(k, v)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess_llm_response\u001b[39m(k, v):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Function to fetch LLM response in parallel.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     answer, context \u001b[38;5;241m=\u001b[39m \u001b[43mget_llm_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectordb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m k, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: v[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: context}\n",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m, in \u001b[0;36mget_llm_response\u001b[0;34m(query, vectordb)\u001b[0m\n\u001b[1;32m      4\u001b[0m context \u001b[38;5;241m=\u001b[39m matching_docs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;241m+\u001b[39m matching_docs[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;241m+\u001b[39m matching_docs[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content\n\u001b[1;32m      5\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBased on the provided paragraph, answer the user question.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mParagraph: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnswer as if you are helpful person answering the user.  Give a concise answer only\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mcontent, context\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 690\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:792\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 792\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/resources/chat/completions.py:863\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    860\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    861\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1278\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1287\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1288\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1055\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1055\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/openai/_base_client.py:1071\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1070\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1074\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1075\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1080\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-MleP4eNCIIMjcaTNaMI7A9vQ on tokens per min (TPM): Limit 30000, Used 28497, Requested 2458. Please try again in 1.91s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "llm_response_data = {}\n",
    "\n",
    "def process_llm_response(k, v):\n",
    "    \"\"\"Function to fetch LLM response in parallel.\"\"\"\n",
    "    answer, context = get_llm_response(v[\"question\"], vectordb)\n",
    "    return k, {\"question\": v[\"question\"], \"answer\": answer, \"context\": context}\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = {executor.submit(process_llm_response, k, v): k for k, v in cleaned_data.items()}\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        k, result = future.result()\n",
    "        llm_response_data[k] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"llm_response_data_agentic.json\", \"w\") as file:\n",
    "    json.dump(llm_response_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7741935483870968 0.6206896551724137 0.5185185185185185 0.7741935483870968\n",
      "0.72 0.3478260869565218 0.19047619047619047 0.4800000000000001\n",
      "0.26086956521739124 0.0909090909090909 0.0 0.21739130434782608\n",
      "0.625 0.3913043478260869 0.27272727272727276 0.5\n",
      "0.3859649122807018 0.2909090909090909 0.18867924528301888 0.3859649122807018\n",
      "0.8235294117647058 0.7499999999999999 0.7333333333333334 0.8235294117647058\n",
      "0.0 0.0 0.0 0.0\n",
      "0.39999999999999997 0.22222222222222224 0.19672131147540983 0.3384615384615384\n",
      "0.16666666666666669 0.0 0.0 0.16666666666666669\n",
      "0.39999999999999997 0.18181818181818182 0.06451612903225806 0.39999999999999997\n",
      "0.3728813559322034 0.14035087719298248 0.07272727272727274 0.3389830508474576\n",
      "0.30000000000000004 0.10526315789473684 0.05555555555555555 0.25\n",
      "0.2978723404255319 0.1333333333333333 0.09302325581395349 0.2978723404255319\n",
      "0.44 0.16666666666666666 0.08695652173913043 0.4000000000000001\n",
      "0.37288135593220345 0.10526315789473684 0.03636363636363637 0.2033898305084746\n",
      "0.3373493975903615 0.19753086419753088 0.1518987341772152 0.16867469879518074\n",
      "0.3076923076923077 0.12 0.08333333333333333 0.2692307692307693\n",
      "0.47619047619047616 0.2950819672131147 0.23728813559322035 0.4444444444444445\n",
      "0.2195121951219512 0.1 0.07692307692307691 0.12195121951219512\n",
      "0.37037037037037035 0.19230769230769232 0.12000000000000001 0.33333333333333326\n",
      "0.43243243243243246 0.1142857142857143 0.0 0.2702702702702703\n",
      "0.27692307692307694 0.15873015873015872 0.09836065573770492 0.24615384615384617\n",
      "0.275 0.15384615384615385 0.10526315789473684 0.275\n",
      "0.44776119402985076 0.276923076923077 0.2222222222222222 0.32835820895522394\n",
      "1.0 1.0 1.0 1.0\n",
      "0.36 0.041666666666666664 0.0 0.16\n",
      "0.4383561643835617 0.1971830985915493 0.08695652173913043 0.273972602739726\n",
      "0.5957446808510639 0.4444444444444445 0.37209302325581395 0.5531914893617023\n",
      "0.30434782608695654 0.11111111111111112 0.045454545454545456 0.21739130434782608\n",
      "0.3023255813953488 0.023809523809523808 0.0 0.186046511627907\n",
      "0.34782608695652173 0.1791044776119403 0.09230769230769231 0.2898550724637681\n",
      "0.5909090909090908 0.47619047619047616 0.39999999999999997 0.4090909090909091\n",
      "0.4235294117647059 0.26506024096385544 0.24691358024691357 0.3764705882352941\n",
      "0.3733333333333333 0.1095890410958904 0.028169014084507043 0.21333333333333332\n",
      "0.4761904761904762 0.2 0.10526315789473685 0.28571428571428564\n",
      "0.3157894736842105 0.21818181818181817 0.18867924528301888 0.28070175438596484\n",
      "0.5581395348837208 0.2926829268292683 0.20512820512820512 0.4186046511627907\n",
      "0.5 0.411764705882353 0.37500000000000006 0.4444444444444444\n",
      "0.717948717948718 0.5945945945945946 0.5142857142857143 0.717948717948718\n",
      "0.24489795918367346 0.0425531914893617 0.0 0.16326530612244897\n",
      "0.32653061224489793 0.12765957446808507 0.04444444444444444 0.20408163265306123\n",
      "0.2318840579710145 0.02985074626865672 0.0 0.17391304347826086\n",
      "0.4666666666666666 0.13793103448275862 0.07142857142857142 0.3\n",
      "0.2222222222222222 0.028571428571428574 0.0 0.16666666666666666\n",
      "0.21818181818181817 0.03773584905660378 0.0 0.10909090909090909\n",
      "0.4776119402985075 0.276923076923077 0.19047619047619047 0.3880597014925373\n",
      "0.5625000000000001 0.4000000000000001 0.21428571428571427 0.43750000000000006\n",
      "0.6774193548387097 0.5333333333333333 0.3793103448275862 0.5161290322580646\n",
      "0.5652173913043478 0.3181818181818182 0.14285714285714282 0.5217391304347826\n",
      "0.68 0.5416666666666666 0.391304347826087 0.64\n",
      "0.4893617021276596 0.3478260869565218 0.28888888888888886 0.42553191489361697\n",
      "0.4485981308411215 0.24761904761904757 0.1553398058252427 0.2803738317757009\n",
      "0.5862068965517241 0.25 0.1111111111111111 0.3793103448275862\n",
      "0.32432432432432434 0.12844036697247707 0.05607476635514018 0.1981981981981982\n",
      "0.3418803418803419 0.1217391304347826 0.08849557522123895 0.2393162393162393\n",
      "0.13043478260869565 0.0 0.0 0.08695652173913043\n",
      "0.4166666666666667 0.1864406779661017 0.15517241379310345 0.3166666666666667\n",
      "0.5565217391304348 0.24778761061946905 0.16216216216216217 0.41739130434782606\n",
      "0.3 0.17241379310344826 0.10714285714285712 0.26666666666666666\n",
      "0.360655737704918 0.13559322033898305 0.03508771929824561 0.26229508196721313\n",
      "0.3764705882352941 0.0963855421686747 0.07407407407407408 0.25882352941176473\n",
      "0.2898550724637681 0.17910447761194032 0.15384615384615385 0.2608695652173913\n",
      "0.4050632911392405 0.15584415584415584 0.08 0.2278481012658228\n",
      "0.3333333333333333 0.15384615384615383 0.04 0.3333333333333333\n",
      "0.34285714285714286 0.18181818181818182 0.1290322580645161 0.28571428571428575\n",
      "0.48 0.33333333333333337 0.30434782608695654 0.44000000000000006\n",
      "0.46511627906976744 0.2926829268292683 0.2564102564102564 0.37209302325581395\n",
      "0.5909090909090908 0.33333333333333337 0.25 0.5\n",
      "0.3181818181818182 0.19047619047619044 0.15 0.3181818181818182\n",
      "0.2708333333333333 0.14893617021276598 0.08695652173913045 0.22916666666666669\n",
      "0.3368421052631579 0.15053763440860216 0.06593406593406594 0.23157894736842105\n",
      "0.7213114754098361 0.47457627118644075 0.2807017543859649 0.5901639344262295\n",
      "0.3428571428571428 0.20588235294117646 0.15151515151515152 0.2571428571428572\n",
      "0.5217391304347826 0.3111111111111111 0.20454545454545456 0.3695652173913043\n",
      "0.34343434343434337 0.2061855670103093 0.16842105263157894 0.2626262626262626\n",
      "0.23333333333333334 0.06896551724137931 0.0 0.16666666666666666\n",
      "0.34285714285714286 0.24242424242424246 0.1935483870967742 0.34285714285714286\n",
      "0.2894736842105263 0.18918918918918917 0.11111111111111112 0.26315789473684215\n",
      "0.2795698924731183 0.17582417582417584 0.15730337078651685 0.21505376344086022\n",
      "0.36363636363636365 0.13333333333333333 0.0273972602739726 0.23376623376623376\n",
      "0.7301587301587301 0.5573770491803278 0.4067796610169491 0.5396825396825397\n",
      "0.4888888888888889 0.3255813953488372 0.24390243902439024 0.26666666666666666\n",
      "0.4827586206896552 0.35714285714285715 0.2962962962962963 0.41379310344827586\n",
      "0.3666666666666667 0.10344827586206896 0.07142857142857142 0.23333333333333334\n",
      "0.2745098039215686 0.18 0.163265306122449 0.25490196078431376\n",
      "0.7111111111111111 0.5581395348837209 0.4390243902439025 0.5777777777777778\n",
      "0.46315789473684205 0.23655913978494625 0.15384615384615385 0.35789473684210527\n",
      "0.4594594594594595 0.13888888888888892 0.0857142857142857 0.35135135135135137\n",
      "0.3846153846153846 0.16 0.08333333333333333 0.1923076923076923\n",
      "0.41269841269841273 0.22950819672131148 0.1694915254237288 0.3174603174603174\n",
      "0.1818181818181818 0.03773584905660377 0.0 0.1818181818181818\n",
      "0.1639344262295082 0.06779661016949154 0.0 0.13114754098360656\n",
      "0.14457831325301204 0.024691358024691357 0.0 0.0963855421686747\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import deepeval\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = open_ai_key\n",
    "\n",
    "test_cases = []\n",
    "for k,v in llm_response_data.items():\n",
    "    question = v[\"question\"]\n",
    "    actual_output = v[\"answer\"]\n",
    "    expected_output = cleaned_data[k][\"answer\"]\n",
    "    retrieval_context = v[\"context\"]\n",
    "    test_case = deepeval.test_case.LLMTestCase(\n",
    "        input=question,\n",
    "        actual_output=actual_output,\n",
    "        expected_output=expected_output,\n",
    "        retrieval_context = [retrieval_context]\n",
    "        )\n",
    "    test_cases.append(test_case)\n",
    "\n",
    "deepeval.evaluate(\n",
    "    test_cases=test_cases,\n",
    "    metrics=[\n",
    "    deepeval.metrics.AnswerRelevancyMetric(),\n",
    "    deepeval.metrics.FaithfulnessMetric(),\n",
    "    deepeval.metrics.ContextualPrecisionMetric(),\n",
    "    deepeval.metrics.ContextualRecallMetric(),\n",
    "    deepeval.metrics.ContextualRelevancyMetric(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ragas import SingleTurnSample, EvaluationDataset\n",
    "\n",
    "\n",
    "# Iterate over llm_response_data and populate the DataFrame\n",
    "data_list = []  # To collect data before creating the DataFrame for efficiency\n",
    "\n",
    "for k, v in llm_response_data.items():\n",
    "    row = SingleTurnSample(\n",
    "        user_input=v[\"question\"],\n",
    "        retrieved_contexts=[v[\"context\"]],\n",
    "        response=v[\"answer\"],\n",
    "        reference=cleaned_data[k][\"answer\"],\n",
    "        reference_contexts = [cleaned_data[k][\"answer\"]]\n",
    "    )\n",
    "\n",
    "    data_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EvaluationDataset(samples=data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   4%|         | 15/372 [02:48<1:04:21, 10.82s/it]ERROR:ragas.executor:Exception raised in Job[9]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[10]: TimeoutError()\n",
      "Evaluating:   4%|         | 16/372 [03:00<1:06:02, 11.13s/it]ERROR:ragas.executor:Exception raised in Job[12]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[2]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[16]: TimeoutError()\n",
      "Evaluating:   5%|         | 20/372 [03:01<25:19,  4.32s/it]  ERROR:ragas.executor:Exception raised in Job[18]: TimeoutError()\n",
      "Evaluating:   6%|         | 23/372 [03:19<36:34,  6.29s/it]ERROR:ragas.executor:Exception raised in Job[20]: TimeoutError()\n",
      "Evaluating:   6%|         | 24/372 [03:29<41:04,  7.08s/it]ERROR:ragas.executor:Exception raised in Job[21]: TimeoutError()\n",
      "Evaluating:   7%|         | 26/372 [03:56<59:54, 10.39s/it]ERROR:ragas.executor:Exception raised in Job[22]: TimeoutError()\n",
      "Evaluating:   7%|         | 27/372 [04:10<1:06:02, 11.49s/it]ERROR:ragas.executor:Exception raised in Job[24]: TimeoutError()\n",
      "Evaluating:   8%|         | 30/372 [04:47<1:01:26, 10.78s/it]ERROR:ragas.executor:Exception raised in Job[25]: TimeoutError()\n",
      "Evaluating:   9%|         | 32/372 [05:08<1:02:16, 10.99s/it]ERROR:ragas.executor:Exception raised in Job[26]: TimeoutError()\n",
      "Evaluating:   9%|         | 33/372 [05:12<50:54,  9.01s/it]  ERROR:ragas.executor:Exception raised in Job[27]: TimeoutError()\n",
      "Evaluating:   9%|         | 35/372 [05:23<38:49,  6.91s/it]ERROR:ragas.executor:Exception raised in Job[28]: TimeoutError()\n",
      "Evaluating:  10%|         | 37/372 [05:50<52:49,  9.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RougeScore, BleuScore, LLMContextPrecisionWithoutReference, LLMContextPrecisionWithReference, LLMContextRecall, ContextEntityRecall, NoiseSensitivity, ResponseRelevancy, NonLLMContextRecall, Faithfulness\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# result = evaluate(dataset, metrics=[RougeScore(), \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#                                     BleuScore()\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#                                     ])\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/ragas/_analytics.py:227\u001b[0m, in \u001b[0;36mtrack_was_completed.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m    226\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/ragas/evaluation.py:298\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[0m\n\u001b[1;32m    295\u001b[0m scores: t\u001b[38;5;241m.\u001b[39mList[t\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, t\u001b[38;5;241m.\u001b[39mAny]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# get the results\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;241m==\u001b[39m []:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/ragas/executor.py:213\u001b[0m, in \u001b[0;36mExecutor.results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m             nest_asyncio\u001b[38;5;241m.\u001b[39mapply()\n\u001b[1;32m    211\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nest_asyncio_applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m sorted_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(results, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m~/anaconda3/envs/rag_advanced/lib/python3.11/selectors.py:468\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout, max_ev)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ragas.executor:Exception raised in Job[34]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[53]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[54]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[55]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[56]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[57]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[58]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[59]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[60]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[61]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[62]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[63]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[64]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[65]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[66]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[67]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[68]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[69]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[70]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[71]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[72]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[73]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[74]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[75]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[76]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[77]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[78]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[79]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[80]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[81]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[82]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[83]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[84]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[85]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[86]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[87]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[88]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[89]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[90]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[91]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[92]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[93]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[94]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[95]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[96]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[97]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[98]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[99]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[100]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[101]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[102]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[103]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[104]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[105]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[106]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[107]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[108]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[109]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[110]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[111]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[112]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[113]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[114]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[115]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[116]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[117]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[118]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[119]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[120]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[121]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[122]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[123]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[124]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[125]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[126]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[127]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[128]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[129]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[130]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[131]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[132]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[133]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[134]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[135]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[136]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[137]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[138]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[139]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[140]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[141]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[142]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[143]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[144]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[145]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[146]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[147]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[148]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[149]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[150]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[151]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[152]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[153]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[154]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[155]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[156]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[157]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[158]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[159]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[160]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[161]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[162]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[163]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[164]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[165]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[166]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[167]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[168]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[169]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[170]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[171]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[172]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[173]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[174]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[175]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[176]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[177]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[178]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[179]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[180]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[181]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[182]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[183]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[184]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[185]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[186]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[187]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[188]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[189]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[190]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[191]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[192]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[193]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[194]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[195]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[196]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[197]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[198]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[199]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[200]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[201]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[202]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[203]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[204]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[205]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[206]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[207]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[208]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[209]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[210]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[211]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[212]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[213]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[214]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[215]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[216]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[217]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[218]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[219]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[220]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[221]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[222]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[223]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[224]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[225]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[226]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[227]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[228]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[229]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[230]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[231]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[232]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[233]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[234]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[235]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[236]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[237]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[238]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[239]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[240]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[241]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[242]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[243]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[244]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[245]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[246]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[247]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[248]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[249]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[250]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[251]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[252]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[253]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[254]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[255]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[256]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[257]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[258]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[259]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[260]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[261]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[262]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[263]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[264]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[265]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[266]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[267]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[268]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[269]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[270]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[271]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[272]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[273]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[274]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[275]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[276]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[277]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[278]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[279]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[280]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[281]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[282]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[283]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[284]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[285]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[286]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[287]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[288]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[289]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[290]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[291]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[292]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[293]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[294]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[295]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[296]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[297]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[298]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[299]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[300]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[301]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[302]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[303]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[304]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[305]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[306]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[307]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[308]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[309]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[310]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[311]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[312]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[313]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[314]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[315]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[316]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[317]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[318]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[319]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[320]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[321]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[322]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[323]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[324]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[325]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[326]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[327]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[328]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[329]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[330]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[331]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[332]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[333]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[334]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[335]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[336]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[337]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[338]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[339]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[340]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[341]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[342]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[343]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[344]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[345]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[346]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[347]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[348]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[349]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[350]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[351]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[352]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[353]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[354]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[355]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[356]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[357]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[358]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[359]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[360]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[361]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[362]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[363]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[364]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[365]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[366]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[367]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[368]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[369]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[370]: AssertionError(LLM is not set)\n",
      "ERROR:ragas.executor:Exception raised in Job[371]: AssertionError(set LLM before use)\n",
      "ERROR:ragas.executor:Exception raised in Job[36]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[38]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[39]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[40]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[44]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "ERROR:ragas.executor:Exception raised in Job[41]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[50]: AssertionError(llm must be set to compute score)\n",
      "ERROR:ragas.executor:Exception raised in Job[46]: AssertionError(llm must be set to compute score)\n",
      "ERROR:ragas.executor:Exception raised in Job[43]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[48]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n",
      "ERROR:ragas.executor:Exception raised in Job[45]: TimeoutError()\n",
      "ERROR:ragas.executor:Exception raised in Job[52]: AssertionError(Error: 'answer_relevancy' requires embeddings to be set.)\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import RougeScore, BleuScore, LLMContextPrecisionWithoutReference, LLMContextPrecisionWithReference, LLMContextRecall, ContextEntityRecall, NoiseSensitivity, ResponseRelevancy, NonLLMContextRecall, Faithfulness\n",
    "\n",
    "result = evaluate(dataset)\n",
    "\n",
    "# result = evaluate(dataset, metrics=[RougeScore(), \n",
    "#                                     BleuScore()\n",
    "#                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge_score': 0.3272, 'bleu_score': 0.1586}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_advanced",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
